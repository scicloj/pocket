---
format:
  html:
    toc: true
    toc-depth: 4
    theme: [cosmo, notebooks/custom.scss]
    toc-expand: 2
    number-depth: 1
    filters: [notebooks/collapse-callouts.lua]

---
<style></style><style>.printedClojure .sourceCode {
  background-color: transparent;
  border-style: none;
}
</style><style>.clay-limit-image-width .clay-image {max-width: 100%}
.clay-side-by-side .sourceCode {margin: 0}
.clay-side-by-side {margin: 1em 0}
</style>
<script src="https://code.jquery.com/jquery-3.6.0.min.js" type="text/javascript"></script><script src="https://code.jquery.com/ui/1.13.1/jquery-ui.min.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/plotly.js/2.20.0/plotly.min.js" type="text/javascript"></script><script src="https://cdn.jsdelivr.net/npm/mermaid@11.10.1/dist/mermaid.min.js" type="text/javascript"></script>

# Example: Machine Learning Workflows

**Last modified: 2026-02-08**

This chapter demonstrates Pocket in a realistic machine learning
scenario. If you're new to ML, don't worry — we'll explain the
concepts as we go. The focus is on how caching helps when you're
exploring many combinations of data, features, and models.

**The problem**: We want to predict a numeric value (like house
prices or temperature) from input data. This is called [*regression*](https://en.wikipedia.org/wiki/Regression_analysis).
We'll generate synthetic data, try different ways of preparing it,
and compare two learning algorithms.

**Why caching matters**: Training models can be slow. When you're
experimenting — tweaking parameters, trying new features — you don't
want to recompute everything each time. Pocket caches each step
independently, so only the parts you changed get recomputed.

**What we'll cover**:

- Part 1: [Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) — transforming inputs to help models learn
- Part 2: Noise sensitivity — how models behave with messy data
- Part 3: The caching payoff — what got cached and why it matters
- Part 4: DAG workflows — when preprocessing steps share dependencies
- Part 5: [Hyperparameter](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) sweeps — comparing many experiments at once

**Note**: This notebook uses
[tablecloth](https://scicloj.github.io/tablecloth/) for data manipulation,
[metamorph.ml](https://github.com/scicloj/metamorph.ml) and
[tribuo](https://github.com/scicloj/scicloj.ml.tribuo) for ML, and
[Plotly.js](https://plotly.com/javascript/) for visualization.
These are not Pocket dependencies — they illustrate a realistic ML
workflow. All output is shown inline; to reproduce it, add
[noj](https://scicloj.github.io/noj/) to your project dependencies.

**Why synthetic data?** Working with synthetic data is a standard
practice in machine learning. Because we define the true relationship
($y = \sin(x) \cdot x$), we can measure exactly how well each model
recovers it — something impossible with real-world data where the
ground truth is unknown. Synthetic experiments let us isolate one
variable at a time: does feature engineering help? How does noise
affect each algorithm? These controlled comparisons build intuition
that transfers to real problems. In our case, we'll see that a linear
model is helpless against a nonlinear target *unless* we give it the
right features, while a [decision tree](https://en.wikipedia.org/wiki/Decision_tree_learning) handles the shape on its own
but pays a different price when noise increases.


## Setup


::: {.sourceClojure}
```clojure
(ns pocket-book.ml-workflows
  (:require
   ;; Logging setup for this chapter (see Logging chapter):
   [pocket-book.logging]
   ;; Pocket API:
   [scicloj.pocket :as pocket]
   ;; Annotating kinds of visualizations:
   [scicloj.kindly.v4.kind :as kind]
   ;; Data processing:
   [tablecloth.api :as tc]
   [tablecloth.column.api :as tcc]
   [tech.v3.dataset :as ds]
   [tech.v3.dataset.modelling :as ds-mod]
   ;; Machine learning:
   [scicloj.metamorph.ml :as ml]
   [scicloj.metamorph.ml.loss :as loss]
   [scicloj.ml.tribuo]))
```
:::



::: {.sourceClojure}
```clojure
(def cache-dir "/tmp/pocket-regression")
```
:::



::: {.sourceClojure}
```clojure
(pocket/set-base-cache-dir! cache-dir)
```
:::



::: {.callout-note}
## OUT
```
22:14:31.961 INFO scicloj.pocket - Cache dir set to: /tmp/pocket-regression

```
:::



::: {.printedClojure}
```clojure
"/tmp/pocket-regression"

```
:::



::: {.sourceClojure}
```clojure
(pocket/cleanup!)
```
:::



::: {.callout-note}
## OUT
```
22:14:31.961 INFO scicloj.pocket - Cache cleanup: /tmp/pocket-regression

```
:::



::: {.printedClojure}
```clojure
{:dir "/tmp/pocket-regression", :existed false}

```
:::



## Pipeline functions

These are the steps of our ML pipeline — plain Clojure functions
that know nothing about caching. Pocket will wrap them later.

**Data generation**: `make-regression-data` creates a synthetic
dataset from a ground-truth function. We control the sample size,
noise level, and random seed — all of which become part of the
cache key, so changing any parameter triggers recomputation.


::: {.sourceClojure}
```clojure
(defn make-regression-data
  "Generate a synthetic regression dataset.
  `f` is a function from x to y (the ground truth).
  Optional `outlier-fraction` (0–1) and `outlier-scale` inject
  corrupted x values to simulate sensor glitches."
  [{:keys [f n noise-sd seed outlier-fraction outlier-scale]
    :or {outlier-fraction 0 outlier-scale 10}}]
  (let [rng (java.util.Random. (long seed))
        xs (vec (repeatedly n #(* 10.0 (.nextDouble rng))))
        xs-final (if (pos? outlier-fraction)
                   (let [out-rng (java.util.Random. (+ (long seed) 7919))]
                     (mapv (fn [x]
                             (if (< (.nextDouble out-rng) outlier-fraction)
                               (+ x (* (double outlier-scale) (.nextGaussian out-rng)))
                               x))
                           xs))
                   xs)
        ys (mapv (fn [x] (+ (double (f x))
                            (* (double noise-sd) (.nextGaussian rng))))
                 xs)]
    (-> (tc/dataset {:x xs-final :y ys})
        (ds-mod/set-inference-target :y))))
```
:::


**Splitting**: `split-dataset` divides data into training and test
sets. This is a cached step so the full provenance chain — from
parameters through data generation to the split — is captured in
the DAG.


::: {.sourceClojure}
```clojure
(defn split-dataset
  "Split a dataset into train/test using holdout."
  [ds {:keys [seed]}]
  (first (tc/split->seq ds :holdout {:seed seed})))
```
:::


**Feature engineering**: `prepare-features` transforms raw data
by adding derived columns. The choice of feature set is a key
hyperparameter — a linear model with only `:raw` features can't
learn nonlinear patterns, but `:trig` or `:poly+trig` features
give it the building blocks it needs.


::: {.sourceClojure}
```clojure
(defn prepare-features
  "Add derived columns to a dataset according to `feature-set`.
  Supported feature sets:

  - `:raw`       — no extra columns
  - `:quadratic` — add x²
  - `:trig`      — add sin(x) and cos(x)
  - `:poly+trig` — add x², sin(x), and cos(x)"
  [ds feature-set]
  (let [x (:x ds)]
    (-> (case feature-set
          :raw ds
          :quadratic (tc/add-columns ds {:x2 (tcc/sq x)})
          :trig (tc/add-columns ds {:sin-x (tcc/sin x)
                                    :cos-x (tcc/cos x)})
          :poly+trig (tc/add-columns ds {:x2 (tcc/sq x)
                                         :sin-x (tcc/sin x)
                                         :cos-x (tcc/cos x)}))
        (ds-mod/set-inference-target :y))))
```
:::


**Training and evaluation**: `train-model` fits a model to
prepared data, and `predict-and-rmse` measures how well it
generalizes to unseen test data. These are thin wrappers
around metamorph.ml — the caching value comes from avoiding
redundant retraining when only downstream parameters change.


::: {.sourceClojure}
```clojure
(defn train-model
  "Train a model on a dataset."
  [train-ds model-spec]
  (ml/train train-ds model-spec))
```
:::



::: {.sourceClojure}
```clojure
(defn predict-and-rmse
  "Predict on test data and return RMSE."
  [test-ds model]
  (let [pred (ml/predict test-ds model)]
    (loss/rmse (:y test-ds) (:y pred))))
```
:::



## Ground truth

We need a function to predict. In real problems you don't know
the true relationship — that's what you're trying to learn. Here
we define it explicitly so we can measure how well our models do.

Our target is $y = \sin(x) \cdot x$ — a wavy curve that grows
with $x$. A straight line can't fit this shape, so a simple
linear model will struggle unless we help it with better features.


::: {.sourceClojure}
```clojure
(defn nonlinear-fn
  "y = sin(x) · x"
  [x]
  (* (Math/sin x) x))
```
:::



## Model specifications

We'll compare two fundamentally different algorithms:

**Linear model** ([gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)): Finds the best straight-line
(or hyperplane) relationship between inputs and output. Simple and
fast, but can only learn linear patterns. Needs good features.

**Decision tree** ([CART](https://en.wikipedia.org/wiki/Decision_tree_learning)): Learns by splitting data into regions
based on thresholds ("if x > 5, go left"). Can capture complex
patterns automatically, but may [overfit](https://en.wikipedia.org/wiki/Overfitting) noisy data.

These algorithms respond differently to feature engineering —
that contrast is the heart of Part 1.


::: {.sourceClojure}
```clojure
(def linear-sgd-spec
  {:model-type :scicloj.ml.tribuo/regression
   :tribuo-components [{:name "squared"
                        :type "org.tribuo.regression.sgd.objectives.SquaredLoss"}
                       {:name "linear-sgd"
                        :type "org.tribuo.regression.sgd.linear.LinearSGDTrainer"
                        :properties {:objective "squared"
                                     :epochs "50"
                                     :loggingInterval "10000"}}]
   :tribuo-trainer-name "linear-sgd"})
```
:::



::: {.sourceClojure}
```clojure
(def cart-spec
  {:model-type :scicloj.ml.tribuo/regression
   :tribuo-components [{:name "cart"
                        :type "org.tribuo.regression.rtree.CARTRegressionTrainer"
                        :properties {:maxDepth "8"}}]
   :tribuo-trainer-name "cart"})
```
:::


---


## Part 1 — Feature engineering matters (for some models)

*Feature engineering* means transforming raw inputs into forms
that help models learn. For example, if the true relationship
involves $x^2$, adding a squared column gives the model that
pattern directly instead of forcing it to discover it.

We'll test four feature sets:

- `:raw` — just the original $x$ value
- `:quadratic` — add $x^2$
- `:trig` — add $\sin(x)$ and $\cos(x)$
- `:poly+trig` — add all three

Crossed with two model types, that's eight combinations. Every
step is cached, so re-running is instant.


### Generate data


::: {.sourceClojure}
```clojure
(def data-c
  (pocket/cached #'make-regression-data
                 {:f #'nonlinear-fn :n 500 :noise-sd 0.5 :seed 42}))
```
:::



::: {.sourceClojure}
```clojure
(tc/head (deref data-c))
```
:::



::: {.callout-note}
## OUT
```
22:14:31.970 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/make-regression-data
22:14:31.973 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/b4/(pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42})

```
:::


::: {.clay-dataset}
_unnamed [5 2]:

|         :x |         :y |
|-----------:|-----------:|
| 7.27563680 | 6.74555252 |
| 6.83223472 | 4.07224915 |
| 3.08719455 | 0.22904859 |
| 2.77078490 | 0.47163659 |
| 6.65548952 | 2.81816258 |


:::



### Split into train and test


::: {.sourceClojure}
```clojure
(def split-c
  (pocket/cached #'split-dataset data-c {:seed 42}))
```
:::


Extract train and test sets — using keywords as cached functions.
The DAG now traces from numerical parameters through data
generation to the split to each subset.


::: {.sourceClojure}
```clojure
(def train-c (pocket/cached :train split-c))
```
:::



::: {.sourceClojure}
```clojure
(def test-c (pocket/cached :test split-c))
```
:::



### Feature sets


::: {.sourceClojure}
```clojure
(def feature-sets [:raw :quadratic :trig :poly+trig])
```
:::



### Prepare features (cached)

Each feature set applied to each split half is a separate
cached computation — eight in total.


::: {.sourceClojure}
```clojure
(def prepared
  (into {}
        (for [fs feature-sets
              [role ds-c] [[:train train-c] [:test test-c]]]
          [[fs role]
           (pocket/cached #'prepare-features ds-c fs)])))
```
:::



### Train models (cached)

Two models per feature set — eight cached training runs.


::: {.sourceClojure}
```clojure
(def models
  (into {}
        (for [fs feature-sets
              [model-name spec] [[:sgd linear-sgd-spec]
                                 [:cart cart-spec]]]
          [[fs model-name]
           (pocket/cached #'train-model
                          (prepared [fs :train])
                          spec)])))
```
:::



### Results


::: {.sourceClojure}
```clojure
(def feature-results
  (vec (for [fs feature-sets
             [model-name _] [[:sgd linear-sgd-spec]
                             [:cart cart-spec]]]
         {:feature-set fs
          :model (name model-name)
          :rmse (predict-and-rmse @(prepared [fs :test])
                                  @(models [fs model-name]))})))
```
:::



::: {.callout-note}
## OUT
```
22:14:31.989 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:31.989 INFO scicloj.pocket.impl.cache - Cache miss, computing: :test
22:14:31.989 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/split-dataset
22:14:31.993 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/e3/(pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42})
22:14:31.994 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/23/(:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42}))
22:14:31.995 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/05/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42})) :raw)
22:14:31.995 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:31.995 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:31.995 INFO scicloj.pocket.impl.cache - Cache miss, computing: :train
22:14:31.996 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/04/(:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42}))
22:14:31.996 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/79/(pocket-book.ml-workflows_prepare-features (:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42})) :raw)
Feb 08, 2026 10:14:31 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:31 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=8.866764,min=-5.501972,mean=0.840206,variance=15.440717})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 7.061050130878382
22:14:32.003 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/c6/c60324b3a114e8d5646efe7ec8bc1d78e743001b
22:14:32.005 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.009 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/1e/1e01826f37666f143cccc6e1883455eb2562ed2e
22:14:32.012 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.013 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/6d/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42})) :quadratic)
22:14:32.013 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.013 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.014 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/06/0644c627bd9ef15c830deb29e333d06403c26a4f
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=8.866764,min=-5.501972,mean=0.840206,variance=15.440717})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 7.746488252108407
22:14:32.019 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/2f/2fdc6bcd8e2009e923d805ad1f2fdc52fc57948e
22:14:32.021 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.030 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/cc/cc330e34b3221a68d7bb7649e629ad6b645e4f47
22:14:32.031 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.032 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/98/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42})) :trig)
22:14:32.032 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.032 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.033 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/9b/(pocket-book.ml-workflows_prepare-features (:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42})) :trig)
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=8.866764,min=-5.501972,mean=0.840206,variance=15.440717})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 0.9717267353378612
22:14:32.041 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/31/31897de14a3f45f4aaf19d0981053c5fb21403cb
22:14:32.042 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.052 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/04/04527115901fc961e204e50922811c525652d96d
22:14:32.057 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.060 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/99/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.5, :seed 42}) {:seed 42})) :poly+trig)
22:14:32.060 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.061 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.063 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/d7/d737f05eb6b2fdcaf7508a2f74277ea684a788ac
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=8.866764,min=-5.501972,mean=0.840206,variance=15.440717})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 1.5031022528715852
22:14:32.072 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/9a/9af00491ae43878968b94538ab45619c1c58f0d9
22:14:32.073 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.084 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/d1/d168df4bc60ad63e27c35709a7e8e2c6b8036407

```
:::



::: {.sourceClojure}
```clojure
feature-results
```
:::



::: {.printedClojure}
```clojure
[{:feature-set :raw, :model "sgd", :rmse 3.6917759873191685}
 {:feature-set :raw, :model "cart", :rmse 0.6334615055076024}
 {:feature-set :quadratic, :model "sgd", :rmse 3.576999082640806}
 {:feature-set :quadratic, :model "cart", :rmse 0.6334615055076024}
 {:feature-set :trig, :model "sgd", :rmse 1.4577701415666355}
 {:feature-set :trig, :model "cart", :rmse 0.6805569759436894}
 {:feature-set :poly+trig, :model "sgd", :rmse 1.3410184469297421}
 {:feature-set :poly+trig, :model "cart", :rmse 0.6805569759436894}]

```
:::


**What the results show**:

The linear model (SGD) has high error with raw features — it's
trying to draw a straight line through a wavy curve. But give it
$\sin(x)$ and $\cos(x)$ as features, and it can combine them to
approximate the true shape. Feature engineering saved the day.

The decision tree (CART) doesn't care. It discovers the wavy
pattern by splitting the data into regions. Extra features
don't help because the tree already found the structure.

**Takeaway**: Some models need feature engineering; others don't.
Caching lets you explore both without waiting.


### Predictions plot

Best linear model (poly+trig) vs best tree (raw) vs actual values.


::: {.sourceClojure}
```clojure
(let [test-ds @(prepared [:raw :test])
      sgd-pred (:y (ml/predict @(prepared [:poly+trig :test])
                               @(models [:poly+trig :sgd])))
      cart-pred (:y (ml/predict test-ds
                                @(models [:raw :cart])))
      xs (vec (:x test-ds))
      actuals (vec (:y test-ds))
      sgd-vals (vec sgd-pred)
      cart-vals (vec cart-pred)]
  (kind/plotly
   {:data [{:x xs :y actuals :mode "markers" :name "actual"
            :marker {:opacity 0.3 :color "gray"}}
           {:x xs :y sgd-vals :mode "markers" :name "Linear SGD (poly+trig)"
            :marker {:opacity 0.5 :color "steelblue"}}
           {:x xs :y cart-vals :mode "markers" :name "CART (raw)"
            :marker {:opacity 0.5 :color "tomato"}}]
    :layout {:xaxis {:title "x"} :yaxis {:title "y"}}}))
```
:::



```{=html}
<div style="height:auto;width:100%;"><script>Plotly.newPlot(document.currentScript.parentElement, [{"x":[9.162937751675898,2.881901760839064,2.8029174071568863,3.036869679733477,5.625339573387319,1.2625782329876534,0.3141823882658079,0.5860358422562673,4.957693996774556,8.374034326981022,2.6064300860884746,5.734770092968069,0.1093489625584243,2.9676876439370483,7.792026912116196,8.93395046645043,8.966972151731754,4.3649097442328655,9.133144945237442,6.556523970243689,1.601307542881809,8.338662354441658,7.275636800328681,5.887273230114029,5.472075167262199,3.938351824714422,2.8989223547759444,9.201028440830354,3.957662801712422,3.3651035217630296,1.9686130088289333,9.974363230557561,4.8057451655643435,3.62495704090968,3.6948638035875394,8.35155555007701,5.451525556016723,1.9614707188185154,3.4616984005044884,6.141067547923854,1.7737847790937833,7.671216444241212,6.655489517945736,6.758508485827457,0.96450915880824,2.0976756886633208,5.601439765052083,3.4475127143085924,2.2197071696876955,4.1885841914666555,6.134693220012867,9.033722646721783,1.2473332045964203,0.4099640693903672,5.735347186765608,3.7435935608900426,6.140948241989225,8.56539414935103,5.6675606560724745,5.648011661650246,2.916564974118041,3.6878291341130565,8.502834502384514,5.943499108896841,3.9095644194007653,4.97332761330185,6.00866554883861,7.754099185924646,1.387953919689331,1.7322564807356011,3.3896250975681763,8.204918233863467,9.674953220085111,5.182172329394712,1.8925476861992896,8.474594867482883,1.7927344087491737,5.8947450865696815,7.0545458753287305,8.053907199213823,1.6616716052142333,1.5865482876736248,7.7046563777394095,0.27314166285965835,3.7101228968376088,3.323242783847485,5.085783849855245,1.6081777232382255,7.829017787900358,1.4459146368031894,2.16418653353231,6.1621368503517875,4.144095098620818,5.148834062231381,1.1041335972159616,5.886407433150332,4.346035045905808,3.691214939418974,1.157501237196259,3.285599644454902,0.14055818452733182,7.034515012832663,0.2702986688213338,5.719031789035535,8.398659092547522,8.718145959648387,9.750075836495604,6.565124808212711,3.614706128921814,0.0629961707988913,6.64921516675779,9.826343569374401,7.455289570035387,6.832234717598454,6.89649109462087,5.563822013190519,5.863145983289133,8.788096664827789,8.336996010963523,8.976338235309475,1.424057611385977,9.622362202497229,5.192654911846663,6.645615310744589,6.436811749976528,5.960541733652932,9.855057258481155,9.633371279771417,5.053441079707084,5.617009436673657,3.8461105379950045,6.152138700739788,8.488935564489962,8.754894014526169,4.946157081511062,1.7701350179026742,0.3370946135386954,6.462319787976428,8.51110551751301,9.32938256811512,3.4026304867449375,9.487981214932969,0.05525250238970103,6.328697913532791,8.295956500501514,7.499061812554475,1.8478953614642224,4.5731709444476945,3.5885662535669116,2.6400242201489443,8.61737213352584,5.260779686454226,5.5087560369206905,5.3040288118184975,7.751206959271756,4.633992710283451,6.998586450671721,0.8503590739546585,7.0926371759746845,5.767354193796422,5.387186886615622,5.373939277251666,3.0871945533265976,9.88548992413256,4.2320168209085365,5.8742738178629565,3.3974710859425796],"y":[2.2660213549185735,0.0719121079533469,0.9089250478396278,0.8933324522986665,-2.3078226486154305,0.5423817085759718,0.3758883372038434,0.33877661328056724,-4.611384189553573,7.738577998933917,0.9284331474668519,-3.6075680351601287,-0.663542680920231,-0.3125819401998935,6.9396563938731175,3.0784465488271215,3.998867689031954,-3.6705311141875923,2.421042020267086,1.0028765919456402,1.7852680667874594,7.02172936037786,6.745552518168166,-2.1728688503639093,-4.524914807180175,-3.5838639123146345,1.3342517301172128,3.0402910919233963,-2.351691147288271,-0.987650214173812,2.3583226730035762,-5.309437979071366,-4.077585983913426,-2.561732227439665,-0.9479740558767714,7.727173653515657,-4.710513305544686,2.0013411073872005,-1.9190996146671055,-1.177297789983929,2.2511105620645737,7.392527679954239,2.818162580004899,2.810483468742886,0.5797844541227521,2.808853985694596,-3.978122195099813,-0.3950200207309057,1.919791883361562,-2.723653369698063,-0.9678294033861969,3.3227008320957045,1.14952923269556,-0.04453481203802759,-3.6742794320668306,-2.4531900801085786,0.08347885493701424,7.356602385978313,-3.008030249975363,-3.060277050948853,0.3031316657045395,-1.9807882334399314,6.030369248309518,-1.6058432729398926,-2.6614031623034253,-4.67024929755079,-1.667633881744998,7.953738363846955,1.3331722179542893,1.50197471059655,-0.455079887736399,8.498491854942527,-2.1568405996442563,-5.052505437293004,1.7111228279856978,7.250860569661639,2.0760613885834385,-1.7794109899930937,4.26227235474898,7.772972307742455,1.5495858163301786,1.6470230915486432,7.586867493488973,0.21634405871113452,-1.9411710834457483,-0.15414129448738628,-4.739397781252117,1.604441372858207,7.320035419570819,0.8687274269214117,2.4947812955613884,-1.1665649888703613,-3.3488922466504274,-4.996600506707139,0.9481471248763733,-2.309072523570158,-4.214356050948241,-1.4621917634971997,-0.030136944689879375,-0.5213420029473248,-0.8021515321179097,4.826732758840118,0.9359096066235159,-2.2509915198061785,6.929814554080055,5.222074404092475,-3.401845840324249,0.7759635311381319,-1.620574047129373,0.534843344125941,2.948957797201813,-3.6981412771770668,7.358982972630106,4.072249153030343,3.484413479495364,-4.169130323062806,-3.042076213988539,4.694043827544608,6.683635329552645,4.447483517409353,1.8964931045300562,-2.198555448084182,-3.711652787294194,2.584967593598159,1.0802115397316976,-2.0093559146377697,-4.015373115008884,-2.3644748494555503,-4.970229712183912,-2.6996797336096017,-2.975580928906157,-0.6692355447629877,6.38223883395862,5.57642776549492,-5.914919334251763,2.407000187536423,0.40158719433522067,1.8005515911759606,6.584583492307075,0.8545369148769743,-1.360292425689122,-1.276419255539152,-0.30162036254098845,0.8946486889116698,6.4405477343447375,6.612581322050381,1.9150359533853594,-4.909848498596979,-1.9379255016445183,1.053622394115376,6.008716108789697,-5.347652163814444,-4.165008466179719,-4.1104372520106045,6.6773488013931015,-4.571719519846841,4.773704738213836,1.0780876224362355,5.78615070031057,-2.5641627859906357,-5.63900950824857,-4.236172244896853,0.22904859105864095,-4.336064458534759,-3.5830483049464648,-1.8467645020387997,-0.31987248865713447],"mode":"markers","name":"actual","marker":{"opacity":0.3,"color":"gray"}},{"x":[9.162937751675898,2.881901760839064,2.8029174071568863,3.036869679733477,5.625339573387319,1.2625782329876534,0.3141823882658079,0.5860358422562673,4.957693996774556,8.374034326981022,2.6064300860884746,5.734770092968069,0.1093489625584243,2.9676876439370483,7.792026912116196,8.93395046645043,8.966972151731754,4.3649097442328655,9.133144945237442,6.556523970243689,1.601307542881809,8.338662354441658,7.275636800328681,5.887273230114029,5.472075167262199,3.938351824714422,2.8989223547759444,9.201028440830354,3.957662801712422,3.3651035217630296,1.9686130088289333,9.974363230557561,4.8057451655643435,3.62495704090968,3.6948638035875394,8.35155555007701,5.451525556016723,1.9614707188185154,3.4616984005044884,6.141067547923854,1.7737847790937833,7.671216444241212,6.655489517945736,6.758508485827457,0.96450915880824,2.0976756886633208,5.601439765052083,3.4475127143085924,2.2197071696876955,4.1885841914666555,6.134693220012867,9.033722646721783,1.2473332045964203,0.4099640693903672,5.735347186765608,3.7435935608900426,6.140948241989225,8.56539414935103,5.6675606560724745,5.648011661650246,2.916564974118041,3.6878291341130565,8.502834502384514,5.943499108896841,3.9095644194007653,4.97332761330185,6.00866554883861,7.754099185924646,1.387953919689331,1.7322564807356011,3.3896250975681763,8.204918233863467,9.674953220085111,5.182172329394712,1.8925476861992896,8.474594867482883,1.7927344087491737,5.8947450865696815,7.0545458753287305,8.053907199213823,1.6616716052142333,1.5865482876736248,7.7046563777394095,0.27314166285965835,3.7101228968376088,3.323242783847485,5.085783849855245,1.6081777232382255,7.829017787900358,1.4459146368031894,2.16418653353231,6.1621368503517875,4.144095098620818,5.148834062231381,1.1041335972159616,5.886407433150332,4.346035045905808,3.691214939418974,1.157501237196259,3.285599644454902,0.14055818452733182,7.034515012832663,0.2702986688213338,5.719031789035535,8.398659092547522,8.718145959648387,9.750075836495604,6.565124808212711,3.614706128921814,0.0629961707988913,6.64921516675779,9.826343569374401,7.455289570035387,6.832234717598454,6.89649109462087,5.563822013190519,5.863145983289133,8.788096664827789,8.336996010963523,8.976338235309475,1.424057611385977,9.622362202497229,5.192654911846663,6.645615310744589,6.436811749976528,5.960541733652932,9.855057258481155,9.633371279771417,5.053441079707084,5.617009436673657,3.8461105379950045,6.152138700739788,8.488935564489962,8.754894014526169,4.946157081511062,1.7701350179026742,0.3370946135386954,6.462319787976428,8.51110551751301,9.32938256811512,3.4026304867449375,9.487981214932969,0.05525250238970103,6.328697913532791,8.295956500501514,7.499061812554475,1.8478953614642224,4.5731709444476945,3.5885662535669116,2.6400242201489443,8.61737213352584,5.260779686454226,5.5087560369206905,5.3040288118184975,7.751206959271756,4.633992710283451,6.998586450671721,0.8503590739546585,7.0926371759746845,5.767354193796422,5.387186886615622,5.373939277251666,3.0871945533265976,9.88548992413256,4.2320168209085365,5.8742738178629565,3.3974710859425796],"y":[2.6418483762505636,0.8131898556637047,1.1496488419427084,0.12270879245540289,-2.5987411478520452,2.6455419298252236,-2.241979471986519,-0.5132117567800236,-4.7250407181580325,6.053848700407769,1.9214334559748538,-2.0811327146776457,-3.631484883655976,0.43506526333088047,6.703937923267417,3.851440574037203,3.68522040267131,-4.7591355538525715,2.8059339288625917,2.4391380333689225,3.369986449959989,6.145681941081091,5.718264374033496,-1.3043197320498807,-3.255609683770914,-3.7252947392036675,0.7391198956802159,2.4297278121027324,-3.7881833326566596,-1.3926375606842143,3.4285930605543884,-1.9700315641271198,-4.909012771564857,-2.5406334412251317,-2.8283603157034136,6.112946487827853,-3.3369705224086803,3.4345223652717793,-1.8306828676580609,0.08870263935812961,3.4910738218701853,6.60148427810292,2.9765475055516832,3.5153681787409328,1.5036193845633665,3.275456801661587,-2.7066833899683997,-1.7670095429269344,3.0536348398142916,-4.427556496498211,0.052720808839085365,3.340059801679393,2.5981311472463204,-1.613487623124946,-2.0783075315341053,-3.0218173170692966,0.08802887735796716,5.450698356710425,-2.4034455570388795,-2.494587105127247,0.6618175980850483,-2.7999306951421774,5.6669990715613805,-1.0045625238318072,-3.6290865637372516,-4.699291535157197,-0.6499315689111462,6.680568098778367,2.987878823828166,3.477244953679568,-1.5047421559650513,6.434070636132158,-0.3109671018161686,-4.236879324598242,3.477670114704976,5.7586839636542555,3.4941769057899092,-1.2648519598653176,4.898241514763282,6.643546477636931,3.4314731776559055,3.3518136704448436,6.637995718083627,-2.516235858155637,-2.889601425501734,-1.2001887087727043,-4.477311056135065,3.3780248467503196,6.718924298705384,3.116944959444549,3.1635238727367065,0.20785880804223922,-4.321541215747252,-4.325163260924626,2.0936413873349267,-1.3088854220648911,-4.730662338130363,-2.8136292462049663,2.2939664257524868,-1.0262518620376726,-3.417076932493367,4.814038733864472,-2.5353291830367213,-2.1578116487400343,5.986184031881884,4.850725061019163,-0.7407260615451543,2.486481895629387,-2.4975170572481638,-3.9509019559144725,2.942997068422917,-1.16925430626877,6.219375859752209,3.8850358190193512,4.194630425354597,-2.8725975435655404,-1.4309455934837638,4.544707920485213,6.149850595840232,3.637510205060993,3.070468670477376,-0.006788275504775676,-4.208017582279361,2.9237131910304717,1.7705261055568213,-0.9125142030163755,-1.3280863171455577,-0.0706416314858247,-4.547706673511709,-2.6365823658924596,-3.4070732834931166,0.15127371130457234,5.712595220977396,4.692257355435175,-4.743233098244957,3.49024577786604,-2.0900683953091574,1.91428043550654,5.639435901923858,1.699355915156615,-1.5639749614649396,0.7769488360788186,-4.004344345825988,1.1564690601793641,6.247991431930296,6.316884592572248,3.491844928881279,-4.955345311852014,-2.386582279477299,1.7971579943383489,5.257626196319127,-4.007830517302736,-3.1062826623674247,-3.869639175629755,6.678454393596263,-4.970677744917518,4.659248083313936,0.9549049669546568,5.054081733700943,-1.9201577680291058,-3.5806483811158047,-3.62868535506208,-0.10756358173632652,-1.4947249447772206,-4.522594948232012,-1.3727017253998577,-1.5404962780681597],"mode":"markers","name":"Linear SGD (poly+trig)","marker":{"opacity":0.5,"color":"steelblue"}},{"x":[9.162937751675898,2.881901760839064,2.8029174071568863,3.036869679733477,5.625339573387319,1.2625782329876534,0.3141823882658079,0.5860358422562673,4.957693996774556,8.374034326981022,2.6064300860884746,5.734770092968069,0.1093489625584243,2.9676876439370483,7.792026912116196,8.93395046645043,8.966972151731754,4.3649097442328655,9.133144945237442,6.556523970243689,1.601307542881809,8.338662354441658,7.275636800328681,5.887273230114029,5.472075167262199,3.938351824714422,2.8989223547759444,9.201028440830354,3.957662801712422,3.3651035217630296,1.9686130088289333,9.974363230557561,4.8057451655643435,3.62495704090968,3.6948638035875394,8.35155555007701,5.451525556016723,1.9614707188185154,3.4616984005044884,6.141067547923854,1.7737847790937833,7.671216444241212,6.655489517945736,6.758508485827457,0.96450915880824,2.0976756886633208,5.601439765052083,3.4475127143085924,2.2197071696876955,4.1885841914666555,6.134693220012867,9.033722646721783,1.2473332045964203,0.4099640693903672,5.735347186765608,3.7435935608900426,6.140948241989225,8.56539414935103,5.6675606560724745,5.648011661650246,2.916564974118041,3.6878291341130565,8.502834502384514,5.943499108896841,3.9095644194007653,4.97332761330185,6.00866554883861,7.754099185924646,1.387953919689331,1.7322564807356011,3.3896250975681763,8.204918233863467,9.674953220085111,5.182172329394712,1.8925476861992896,8.474594867482883,1.7927344087491737,5.8947450865696815,7.0545458753287305,8.053907199213823,1.6616716052142333,1.5865482876736248,7.7046563777394095,0.27314166285965835,3.7101228968376088,3.323242783847485,5.085783849855245,1.6081777232382255,7.829017787900358,1.4459146368031894,2.16418653353231,6.1621368503517875,4.144095098620818,5.148834062231381,1.1041335972159616,5.886407433150332,4.346035045905808,3.691214939418974,1.157501237196259,3.285599644454902,0.14055818452733182,7.034515012832663,0.2702986688213338,5.719031789035535,8.398659092547522,8.718145959648387,9.750075836495604,6.565124808212711,3.614706128921814,0.0629961707988913,6.64921516675779,9.826343569374401,7.455289570035387,6.832234717598454,6.89649109462087,5.563822013190519,5.863145983289133,8.788096664827789,8.336996010963523,8.976338235309475,1.424057611385977,9.622362202497229,5.192654911846663,6.645615310744589,6.436811749976528,5.960541733652932,9.855057258481155,9.633371279771417,5.053441079707084,5.617009436673657,3.8461105379950045,6.152138700739788,8.488935564489962,8.754894014526169,4.946157081511062,1.7701350179026742,0.3370946135386954,6.462319787976428,8.51110551751301,9.32938256811512,3.4026304867449375,9.487981214932969,0.05525250238970103,6.328697913532791,8.295956500501514,7.499061812554475,1.8478953614642224,4.5731709444476945,3.5885662535669116,2.6400242201489443,8.61737213352584,5.260779686454226,5.5087560369206905,5.3040288118184975,7.751206959271756,4.633992710283451,6.998586450671721,0.8503590739546585,7.0926371759746845,5.767354193796422,5.387186886615622,5.373939277251666,3.0871945533265976,9.88548992413256,4.2320168209085365,5.8742738178629565,3.3974710859425796],"y":[2.0494627555211387,0.920036643743515,1.2817705869674683,-0.03710518404841423,-3.5514585177103677,1.076704098118676,-0.45550280809402466,-0.014642383903265,-4.545772535460336,7.450884461402892,1.537168187754495,-3.5394774675369263,-0.15743271040264517,0.920036643743515,7.893579938194968,4.465291500091553,3.9001137614250183,-4.545772535460336,2.0494627555211387,1.7209413647651672,1.856018982150338,7.450884461402892,5.816326300303142,-2.0323322415351868,-3.910042476654053,-2.6137142521994456,0.920036643743515,2.378809849421183,-2.6137142521994456,-0.32726822296778363,1.856018982150338,-5.029242833455403,-4.545772535460336,-1.8873282074928284,-1.8873282074928284,7.450884461402892,-3.910042476654053,1.856018982150338,-1.4506986141204834,-0.677547832330068,1.856018982150338,7.893579938194968,1.8940662542978923,3.2319266200065613,2.1714389324188232,1.856018982150338,-3.5514585177103677,-1.4506986141204834,1.856018982150338,-3.3673548221588137,-0.677547832330068,2.8883135318756104,1.076704098118676,0.7029594331979752,-3.5394774675369263,-2.8382390340169272,-0.677547832330068,5.884231431143624,-3.5514585177103677,-3.5514585177103677,0.920036643743515,-1.8873282074928284,6.301878452301025,-1.619015653928121,-2.6137142521994456,-4.545772535460336,-2.236023426055908,7.893579938194968,1.611088607992445,1.856018982150338,-0.32726822296778363,7.450884461402892,-3.0457497437795005,-4.545772535460336,1.856018982150338,6.301878452301025,1.856018982150338,-2.0323322415351868,4.459895610809326,7.893579938194968,1.856018982150338,1.856018982150338,7.893579938194968,0.13135595619678497,-1.8873282074928284,-0.1268192157149315,-4.545772535460336,1.856018982150338,7.893579938194968,1.611088607992445,1.856018982150338,-0.677547832330068,-3.3673548221588137,-4.545772535460336,1.076704098118676,-2.0323322415351868,-3.691183090209961,-1.8873282074928284,1.076704098118676,-0.1268192157149315,-0.15743271040264517,4.459895610809326,0.13135595619678497,-2.6570186614990234,7.450884461402892,5.884231431143624,-2.999164640903473,1.7209413647651672,-1.8873282074928284,0.06356617125372091,1.8940662542978923,-3.590810537338257,6.62187623977661,4.049823919932048,3.8282152811686196,-3.5514585177103677,-2.0323322415351868,5.884231431143624,7.450884461402892,3.9001137614250183,1.611088607992445,-1.5354740222295125,-4.545772535460336,1.8940662542978923,1.5193911790847778,-1.619015653928121,-3.590810537338257,-1.5354740222295125,-4.545772535460336,-3.5514585177103677,-2.058987617492676,-0.677547832330068,6.301878452301025,5.884231431143624,-4.545772535460336,1.856018982150338,0.7029594331979752,1.5193911790847778,5.884231431143624,0.8281522492567698,-0.32726822296778363,-0.2012165393680334,0.06356617125372091,0.9580957293510437,7.450884461402892,7.159455871582031,1.856018982150338,-4.545772535460336,-1.4506986141204834,1.537168187754495,5.884231431143624,-4.545772535460336,-3.5514585177103677,-4.545772535460336,7.893579938194968,-4.545772535460336,5.13687002658844,0.4476439654827118,5.4917826652526855,-2.681432843208313,-3.910042476654053,-5.45878791809082,-0.6944498121738434,-3.590810537338257,-3.039973258972168,-2.0323322415351868,-0.32726822296778363],"mode":"markers","name":"CART (raw)","marker":{"opacity":0.5,"color":"tomato"}}], {"xaxis":{"title":"x"},"yaxis":{"title":"y"}}, {});</script></div>
```


---


## Part 2 — How models handle noisy data

Real data is messy. Measurements have errors, inputs are approximate.
*Noise* is the random variation that obscures the true pattern.

How do our models behave as noise increases? We'll test five
levels, from nearly clean (0.1) to very noisy (5.0).

Notice: the noise=0.5 dataset reuses the cache from Part 1 —
Pocket recognizes the same function and arguments.


::: {.sourceClojure}
```clojure
(def noise-levels [0.1 0.5 1.0 2.0 5.0])
```
:::



::: {.sourceClojure}
```clojure
(def noise-results
  (vec
   (for [noise-sd noise-levels]
     (let [data-c (pocket/cached #'make-regression-data
                                 {:f #'nonlinear-fn :n 500 :noise-sd noise-sd :seed 42})
           split-c (pocket/cached #'split-dataset data-c {:seed 42})
           train-c (pocket/cached :train split-c)
           test-c (pocket/cached :test split-c)
           cart-train (pocket/cached #'prepare-features train-c :raw)
           cart-test (pocket/cached #'prepare-features test-c :raw)
           sgd-train (pocket/cached #'prepare-features train-c :poly+trig)
           sgd-test (pocket/cached #'prepare-features test-c :poly+trig)
           cart-model (pocket/cached #'train-model cart-train cart-spec)
           sgd-model (pocket/cached #'train-model sgd-train linear-sgd-spec)]
       {:noise-sd noise-sd
        :cart-rmse (predict-and-rmse @cart-test @cart-model)
        :sgd-rmse (predict-and-rmse @sgd-test @sgd-model)}))))
```
:::



::: {.callout-note}
## OUT
```
22:14:32.097 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.097 INFO scicloj.pocket.impl.cache - Cache miss, computing: :test
22:14:32.097 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/split-dataset
22:14:32.097 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/make-regression-data
22:14:32.098 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/6a/(pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.1, :seed 42})
22:14:32.100 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/3a/(pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.1, :seed 42}) {:seed 42})
22:14:32.100 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/94/(:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.1, :seed 42}) {:seed 42}))
22:14:32.101 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/96/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.1, :seed 42}) {:seed 42})) :raw)
22:14:32.101 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.101 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.101 INFO scicloj.pocket.impl.cache - Cache miss, computing: :train
22:14:32.101 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/55/(:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.1, :seed 42}) {:seed 42}))
22:14:32.102 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/08/(pocket-book.ml-workflows_prepare-features (:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.1, :seed 42}) {:seed 42})) :raw)
22:14:32.107 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/b8/b852ace3759232f1dec48d3e01572a918e9e31e6
22:14:32.108 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.109 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/dd/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 0.1, :seed 42}) {:seed 42})) :poly+trig)
22:14:32.109 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.109 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.110 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/bc/bcc1185d8c044fe468f72f058191a99f73c4ea91
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=8.106624,min=-5.332393,mean=0.805881,variance=15.304966})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 1.4235088958624642
22:14:32.115 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/82/82fcdba4291961e398a2dabf02049538d45de7ff
22:14:32.118 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.118 INFO scicloj.pocket.impl.cache - Cache miss, computing: :test
22:14:32.118 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/split-dataset
22:14:32.118 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/make-regression-data
22:14:32.119 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/53/(pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 1.0, :seed 42})
22:14:32.121 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/68/(pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 1.0, :seed 42}) {:seed 42})
22:14:32.121 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/85/(:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 1.0, :seed 42}) {:seed 42}))
22:14:32.121 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/d1/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 1.0, :seed 42}) {:seed 42})) :raw)
22:14:32.121 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.121 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.122 INFO scicloj.pocket.impl.cache - Cache miss, computing: :train
22:14:32.122 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/62/(:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 1.0, :seed 42}) {:seed 42}))
22:14:32.122 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/ac/(pocket-book.ml-workflows_prepare-features (:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 1.0, :seed 42}) {:seed 42})) :raw)
22:14:32.127 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/56/56b12a0b688bc09e6b02b1079e0b3db9e27780bb
22:14:32.128 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.130 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/3d/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 1.0, :seed 42}) {:seed 42})) :poly+trig)
22:14:32.130 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.130 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.131 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/21/2138858cf3d145d3b1dda31f1fbff57c42021903
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=9.816940,min=-6.625413,mean=0.883112,variance=15.979208})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 1.8153008504655874
22:14:32.139 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/af/afcc6439d95dc6b19a47d7bb13b405a6e3f7bf75
22:14:32.140 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.140 INFO scicloj.pocket.impl.cache - Cache miss, computing: :test
22:14:32.140 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/split-dataset
22:14:32.140 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/make-regression-data
22:14:32.141 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/1f/(pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 2.0, :seed 42})
22:14:32.143 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/ec/(pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 2.0, :seed 42}) {:seed 42})
22:14:32.143 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/a2/(:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 2.0, :seed 42}) {:seed 42}))
22:14:32.144 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/b0/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 2.0, :seed 42}) {:seed 42})) :raw)
22:14:32.144 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.144 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.144 INFO scicloj.pocket.impl.cache - Cache miss, computing: :train
22:14:32.145 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/be/(:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 2.0, :seed 42}) {:seed 42}))
22:14:32.145 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/d8/(pocket-book.ml-workflows_prepare-features (:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 2.0, :seed 42}) {:seed 42})) :raw)
22:14:32.149 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/42/4283017d384a0edb1360ed439ce2022cded0120a
22:14:32.151 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.151 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/9a/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 2.0, :seed 42}) {:seed 42})) :poly+trig)
22:14:32.151 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.151 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.152 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/c5/c596cf0eff32ed864e9956ede9b9f1a8ba604d8a
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=11.717291,min=-8.958664,mean=0.968924,variance=18.285525})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 3.123027977933463
22:14:32.157 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/e7/e73082ba807aa7585ee9bfe055500e1478428bfb
22:14:32.158 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.158 INFO scicloj.pocket.impl.cache - Cache miss, computing: :test
22:14:32.158 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/split-dataset
22:14:32.158 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/make-regression-data
22:14:32.159 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/16/(pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 5.0, :seed 42})
22:14:32.160 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/33/(pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 5.0, :seed 42}) {:seed 42})
22:14:32.161 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/f6/(:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 5.0, :seed 42}) {:seed 42}))
22:14:32.161 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/1d/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 5.0, :seed 42}) {:seed 42})) :raw)
22:14:32.161 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.161 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.161 INFO scicloj.pocket.impl.cache - Cache miss, computing: :train
22:14:32.162 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/b2/(:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 5.0, :seed 42}) {:seed 42}))
22:14:32.162 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/c0/(pocket-book.ml-workflows_prepare-features (:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 5.0, :seed 42}) {:seed 42})) :raw)
22:14:32.166 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/41/4125ad81cf3bdb18d7b227f84c899e30d5692f27
22:14:32.167 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.168 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/2a/(pocket-book.ml-workflows_prepare-features (:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 500, :noise-sd 5.0, :seed 42}) {:seed 42})) :poly+trig)
22:14:32.168 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.169 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/prepare-features
22:14:32.169 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/2a/2ab54b2e292bd3cd5f65f72be9ddd1b0a17c3de8
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Training SGD model with 333 examples
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: Outputs - RegressionInfo({name=y,id=0,count=333,max=17.418345,min=-15.958416,mean=1.226360,variance=35.039175})
Feb 08, 2026 10:14:32 PM org.tribuo.common.sgd.AbstractSGDTrainer train
INFO: At iteration 10000, average loss = 12.1030268449752
22:14:32.176 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/53/533425c770f1d0b6600c387d76730e7b41036713

```
:::



::: {.sourceClojure}
```clojure
noise-results
```
:::



::: {.printedClojure}
```clojure
[{:noise-sd 0.1,
  :cart-rmse 0.18813079748027944,
  :sgd-rmse 1.2744431229599325}
 {:noise-sd 0.5,
  :cart-rmse 0.6334615055076024,
  :sgd-rmse 1.3410184469297421}
 {:noise-sd 1.0,
  :cart-rmse 1.2499664669902657,
  :sgd-rmse 1.582298583473656}
 {:noise-sd 2.0,
  :cart-rmse 2.453719422103725,
  :sgd-rmse 2.352662287937308}
 {:noise-sd 5.0,
  :cart-rmse 5.960858808406107,
  :sgd-rmse 5.262029923696976}]

```
:::


**What the results show**:

At low noise, the tree wins — it captures fine details the linear
model smooths over. But as noise increases, the tree starts
memorizing random wiggles (*overfitting*), and its error explodes.

The linear model degrades more gracefully. Its rigid structure
(a weighted sum of features) acts as a built-in [regularizer](https://en.wikipedia.org/wiki/Regularization_(mathematics)) —
it can't chase noise even if it wanted to.

**Takeaway**: Flexible models (trees) excel with clean data but
suffer with noise. Simple models (linear) are more robust.


### [RMSE](https://en.wikipedia.org/wiki/Root_mean_square_deviation) vs. noise


::: {.sourceClojure}
```clojure
(let [noise-sds (vec (map :noise-sd noise-results))
      cart-rmses (vec (map :cart-rmse noise-results))
      sgd-rmses (vec (map :sgd-rmse noise-results))]
  (kind/plotly
   {:data [{:x noise-sds :y cart-rmses :mode "lines+markers" :name "CART"}
           {:x noise-sds :y sgd-rmses :mode "lines+markers" :name "Linear SGD"}]
    :layout {:xaxis {:title "noise-sd"} :yaxis {:title "rmse"}}}))
```
:::



```{=html}
<div style="height:auto;width:100%;"><script>Plotly.newPlot(document.currentScript.parentElement, [{"x":[0.1,0.5,1.0,2.0,5.0],"y":[0.18813079748027944,0.6334615055076024,1.2499664669902657,2.453719422103725,5.960858808406107],"mode":"lines+markers","name":"CART"},{"x":[0.1,0.5,1.0,2.0,5.0],"y":[1.2744431229599325,1.3410184469297421,1.582298583473656,2.352662287937308,5.262029923696976],"mode":"lines+markers","name":"Linear SGD"}], {"xaxis":{"title":"noise-sd"},"yaxis":{"title":"rmse"}}, {});</script></div>
```


---


## Part 3 — What got cached?

We've run many combinations of data, features, and models.
Each `pocket/cached` call created an independent cache entry.
Let's see what we accumulated:


::: {.sourceClojure}
```clojure
(:total-entries (pocket/cache-stats))
```
:::



::: {.printedClojure}
```clojure
60

```
:::



::: {.sourceClojure}
```clojure
(:entries-per-fn (pocket/cache-stats))
```
:::



::: {.printedClojure}
```clojure
{"pocket-book.ml-workflows/train-model" 16,
 "pocket-book.ml-workflows/prepare-features" 24,
 "pocket-book.ml-workflows/make-regression-data" 5,
 ":test" 5,
 ":train" 5,
 "pocket-book.ml-workflows/split-dataset" 5}

```
:::


With this small synthetic data, each step runs in milliseconds.
But the *structure* is what matters. In real workflows — large
datasets, deep neural networks, hyperparameter searches — the
same cache graph saves hours or days.

Here's what happens when you change something:

| Change                        | What recomputes          |
|-------------------------------|--------------------------|
| Edit a feature set            | That feature prep + its models |
| Change a model hyperparameter | Only that model          |
| Change the noise level        | That data + its features + its models |
| Re-run the whole notebook     | Nothing — all cached     |


## Cleanup


::: {.sourceClojure}
```clojure
(pocket/cleanup!)
```
:::



::: {.callout-note}
## OUT
```
22:14:32.202 INFO scicloj.pocket - Cache cleanup: /tmp/pocket-regression

```
:::



::: {.printedClojure}
```clojure
{:dir "/tmp/pocket-regression", :existed true}

```
:::


---


## Part 4 — Sharing computations across branches

Real sensors glitch. A positioning system occasionally records a
wildly wrong x value — the physics (y) is unaffected, but the
recorded input is corrupted. When we build polynomial features
like x², these outlier x values get amplified: an errant x=50
gives x²=2500 instead of the expected ~25 from a normal x≈5.

The fix is *feature outlier clipping*: compute what range of x is
"normal" from training data, then clip both train and test inputs
to those bounds — **before** feature engineering.

The clipping threshold **must** come from training data alone.
Using test data would leak future information.

This creates a *diamond dependency* — one computation (the
threshold) feeds into multiple downstream steps:

```
 make-regression-data (with x outliers)
         |
    split-dataset
         |
    +----+----+
    v         v
 (:train)  (:test)
    |         |
    v         |
fit-threshold |
    |         |
    +----+----+
    v         v
clip(train) clip(test)
    |         |
    v         v
features   features
    |         |
    v         |
train-model   |
    |         |
    +----+----+
    v
  evaluate
```

Pocket handles this naturally. The threshold node is computed once
and feeds both clipping steps. When you change the training data,
the threshold recomputes, and both branches update.


### Pipeline functions

These are plain functions. Each does one thing: fit a threshold,
clip outliers, or evaluate. Pocket will wire them together.


::: {.sourceClojure}
```clojure
(defn fit-outlier-threshold
  "Compute IQR-based clipping bounds for :x from training data.
  Returns {:lower <bound> :upper <bound>}."
  [train-ds]
  (println "  Fitting outlier threshold from training data...")
  (let [xs (sort (vec (:x train-ds)))
        n (count xs)
        q1 (nth xs (int (* 0.25 n)))
        q3 (nth xs (int (* 0.75 n)))
        iqr (- q3 q1)]
    {:lower (- q1 (* 1.5 iqr))
     :upper (+ q3 (* 1.5 iqr))}))
```
:::



::: {.sourceClojure}
```clojure
(defn clip-outliers
  "Clip :x values using pre-computed threshold bounds."
  [ds threshold]
  (println "  Clipping outliers with bounds:" (select-keys threshold [:lower :upper]))
  (let [{:keys [lower upper]} threshold]
    (tc/add-column ds :x (-> (:x ds) (tcc/max lower) (tcc/min upper)))))
```
:::



::: {.sourceClojure}
```clojure
(defn evaluate-model
  "Evaluate a model on test data."
  [test-ds model]
  (println "  Evaluating model...")
  (let [pred (ml/predict test-ds model)]
    {:rmse (loss/rmse (:y test-ds) (:y pred))}))
```
:::



### Build the DAG with mixed storage policies

Not every step needs disk persistence. We use `caching-fn` with
per-function storage policies:


- **`:mem`** for cheap shared computations (threshold, clipping,
  feature engineering) — no disk I/O, but in-memory dedup ensures
  each runs only once
  persists across JVM sessions

- **`:none`** for trivial steps (evaluation) — just tracks identity
  in the DAG without any shared caching


::: {.sourceClojure}
```clojure
(def c-fit-threshold
  (pocket/caching-fn #'fit-outlier-threshold {:storage :mem}))
```
:::



::: {.sourceClojure}
```clojure
(def c-clip
  (pocket/caching-fn #'clip-outliers {:storage :mem}))
```
:::



::: {.sourceClojure}
```clojure
(def c-prepare
  (pocket/caching-fn #'prepare-features {:storage :mem}))
```
:::



::: {.sourceClojure}
```clojure
(def c-train
  (pocket/caching-fn #'train-model))
```
:::



::: {.sourceClojure}
```clojure
(def c-evaluate
  (pocket/caching-fn #'evaluate-model {:storage :none}))
```
:::


Generate data *with outliers* for this demo — 10% of the x values
are corrupted by large random spikes, simulating sensor glitches.
The y values (physics) are computed from the clean x, then noise
is added normally — so only the input is corrupted.


::: {.sourceClojure}
```clojure
(def dag-data-c
  (pocket/cached #'make-regression-data
                 {:f #'nonlinear-fn :n 200 :noise-sd 0.3 :seed 99
                  :outlier-fraction 0.1 :outlier-scale 15}))
```
:::



::: {.sourceClojure}
```clojure
(def dag-split-c
  (pocket/cached #'split-dataset dag-data-c {:seed 99}))
```
:::



::: {.sourceClojure}
```clojure
(def dag-train-c (pocket/cached :train dag-split-c))
```
:::



::: {.sourceClojure}
```clojure
(def dag-test-c (pocket/cached :test dag-split-c))
```
:::


Now wire the pipeline. The threshold is fitted once from training
data (in memory) and feeds both clipping steps — a diamond
dependency handled naturally.


::: {.sourceClojure}
```clojure
(def threshold-c
  (c-fit-threshold dag-train-c))
```
:::



::: {.sourceClojure}
```clojure
(def train-clipped-c
  (c-clip dag-train-c threshold-c))
```
:::



::: {.sourceClojure}
```clojure
(def test-clipped-c
  (c-clip dag-test-c threshold-c))
```
:::



::: {.sourceClojure}
```clojure
(def train-prepped-c
  (c-prepare train-clipped-c :poly+trig))
```
:::



::: {.sourceClojure}
```clojure
(def test-prepped-c
  (c-prepare test-clipped-c :poly+trig))
```
:::



::: {.sourceClojure}
```clojure
(def model-c
  (c-train train-prepped-c cart-spec))
```
:::



::: {.sourceClojure}
```clojure
(def metrics-c
  (c-evaluate test-prepped-c model-c))
```
:::



### Visualize the DAG

Pocket provides three functions for DAG introspection, each suited
to different use cases.

**`origin-story`** returns a nested tree structure. Each cached node
has `:fn`, `:args`, and `:id`. The `:id` is unique; when the same
`Cached` instance appears multiple times (diamond pattern), subsequent
occurrences become `{:ref <id>}` pointers. This avoids infinite
recursion and makes the diamond explicit:


::: {.sourceClojure}
```clojure
(pocket/origin-story metrics-c)
```
:::



::: {.printedClojure}
```clojure
{:fn #'pocket-book.ml-workflows/evaluate-model,
 :args
 [{:fn #'pocket-book.ml-workflows/prepare-features,
   :args
   [{:fn #'pocket-book.ml-workflows/clip-outliers,
     :args
     [{:fn :test,
       :args
       [{:fn #'pocket-book.ml-workflows/split-dataset,
         :args
         [{:fn #'pocket-book.ml-workflows/make-regression-data,
           :args
           [{:value
             {:f #'pocket-book.ml-workflows/nonlinear-fn,
              :n 200,
              :noise-sd 0.3,
              :seed 99,
              :outlier-fraction 0.1,
              :outlier-scale 15}}],
           :id "c6"}
          {:value {:seed 99}}],
         :id "c5"}],
       :id "c4"}
      {:fn #'pocket-book.ml-workflows/fit-outlier-threshold,
       :args [{:fn :train, :args [{:ref "c5"}], :id "c8"}],
       :id "c7"}],
     :id "c3"}
    {:value :poly+trig}],
   :id "c2"}
  {:fn #'pocket-book.ml-workflows/train-model,
   :args
   [{:fn #'pocket-book.ml-workflows/prepare-features,
     :args
     [{:fn #'pocket-book.ml-workflows/clip-outliers,
       :args [{:ref "c8"} {:ref "c7"}],
       :id "c11"}
      {:value :poly+trig}],
     :id "c10"}
    {:value
     {:model-type :scicloj.ml.tribuo/regression,
      :tribuo-components
      [{:name "cart",
        :type "org.tribuo.regression.rtree.CARTRegressionTrainer",
        :properties {:maxDepth "8"}}],
      :tribuo-trainer-name "cart"}}],
   :id "c9"}],
 :id "c1"}

```
:::


Notice how the threshold node appears as a `:ref` in one branch —
it's the same computation feeding both train and test clipping.

**`origin-story-graph`** normalizes the tree into a flat
`{:nodes ... :edges ...}` structure suitable for graph algorithms:


::: {.sourceClojure}
```clojure
(pocket/origin-story-graph metrics-c)
```
:::



::: {.printedClojure}
```clojure
{:nodes
 {"c9" {:fn #'pocket-book.ml-workflows/fit-outlier-threshold},
  "c10" {:fn :train},
  "c13" {:fn #'pocket-book.ml-workflows/prepare-features},
  "c14" {:fn #'pocket-book.ml-workflows/clip-outliers},
  "v15" {:value :poly+trig},
  "v7"
  {:value
   {:f #'pocket-book.ml-workflows/nonlinear-fn,
    :n 200,
    :noise-sd 0.3,
    :seed 99,
    :outlier-fraction 0.1,
    :outlier-scale 15}},
  "v8" {:value {:seed 99}},
  "c2" {:fn #'pocket-book.ml-workflows/prepare-features},
  "v11" {:value :poly+trig},
  "c12" {:fn #'pocket-book.ml-workflows/train-model},
  "v16"
  {:value
   {:model-type :scicloj.ml.tribuo/regression,
    :tribuo-components
    [{:name "cart",
      :type "org.tribuo.regression.rtree.CARTRegressionTrainer",
      :properties {:maxDepth "8"}}],
    :tribuo-trainer-name "cart"}},
  "c3" {:fn #'pocket-book.ml-workflows/clip-outliers},
  "c4" {:fn :test},
  "c5" {:fn #'pocket-book.ml-workflows/split-dataset},
  "c6" {:fn #'pocket-book.ml-workflows/make-regression-data},
  "c1" {:fn #'pocket-book.ml-workflows/evaluate-model}},
 :edges
 [["c1" "c2"]
  ["c2" "c3"]
  ["c3" "c4"]
  ["c4" "c5"]
  ["c5" "c6"]
  ["c6" "v7"]
  ["c5" "v8"]
  ["c3" "c9"]
  ["c9" "c10"]
  ["c10" "c5"]
  ["c2" "v11"]
  ["c1" "c12"]
  ["c12" "c13"]
  ["c13" "c14"]
  ["c14" "c10"]
  ["c14" "c9"]
  ["c13" "v15"]
  ["c12" "v16"]]}

```
:::


**`origin-story-mermaid`** renders the DAG as a Mermaid flowchart, with
arrows showing data flow direction (from inputs toward the final result).
The diamond dependency is clearly visible — the threshold feeds both
clipping steps:


::: {.sourceClojure}
```clojure
(pocket/origin-story-mermaid metrics-c)
```
:::



```{=html}
<div class="mermaid">flowchart TD
  n0["evaluate-model"]
  n1["prepare-features"]
  n2["clip-outliers"]
  n3[":test"]
  n4["split-dataset"]
  n5["make-regression-data"]
  n6[/"{:f #'pocket-book.ml-workflows/nonlinear-fn,<br>:n 200,<br>:noise-sd 0.3,<br>:seed 99,<br>:outlier-fraction 0.1,<br>:outlier-scale 15}"/]
  n6 --> n5
  n5 --> n4
  n7[/"{:seed 99}"/]
  n7 --> n4
  n4 --> n3
  n3 --> n2
  n8["fit-outlier-threshold"]
  n9[":train"]
  n4 --> n9
  n9 --> n8
  n8 --> n2
  n2 --> n1
  n10[/":poly+trig"/]
  n10 --> n1
  n1 --> n0
  n11["train-model"]
  n12["prepare-features"]
  n13["clip-outliers"]
  n9 --> n13
  n8 --> n13
  n13 --> n12
  n14[/":poly+trig"/]
  n14 --> n12
  n12 --> n11
  n15[/"{:model-type :scicloj.ml.tribuo/regression,<br>:tribuo-components [{:name 'cart',<br>:type 'org.tribuo.regression.rtree.CARTRegressionTrainer',<br>:properties {:maxDepth '8'}}],<br>:tribuo-trainer-name 'cart'}"/]
  n15 --> n11
  n11 --> n0</div>
```



### Execute the pipeline


::: {.sourceClojure}
```clojure
(deref metrics-c)
```
:::



::: {.callout-note}
## OUT
```
22:14:32.210 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/prepare-features
22:14:32.210 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/clip-outliers
22:14:32.210 INFO scicloj.pocket.impl.cache - Cache miss, computing: :test
22:14:32.210 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/split-dataset
22:14:32.210 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/make-regression-data
22:14:32.211 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/19/(pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :outlier-fraction 0.1, :outlier-scale 15, :seed 99})
22:14:32.212 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/53/(pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :outlier-fraction 0.1, :outlier-scale 15, :seed 99}) {:seed 99})
22:14:32.213 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/fb/(:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :outlier-fraction 0.1, :outlier-scale 15, :seed 99}) {:seed 99}))
22:14:32.213 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/fit-outlier-threshold
22:14:32.213 INFO scicloj.pocket.impl.cache - Cache miss, computing: :train
22:14:32.213 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/09/(:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :outlier-fraction 0.1, :outlier-scale 15, :seed 99}) {:seed 99}))
  Fitting outlier threshold from training data...
  Clipping outliers with bounds: {:lower -5.499694170624462, :upper 15.994051959902624}
22:14:32.214 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.214 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/prepare-features
22:14:32.214 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/clip-outliers
  Clipping outliers with bounds: {:lower -5.499694170624462, :upper 15.994051959902624}
22:14:32.219 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/29/298735d4cc3dbde1964a5f86130dba60f3a9db43
  Evaluating model...

```
:::



::: {.printedClojure}
```clojure
{:rmse 1.601302555211606}

```
:::


How much did clipping help? Let's compare three scenarios
using the same cached building blocks.

The no-clip and clean-baseline pipelines are local — they exist
only for this comparison. Each still builds a cached DAG that
shares steps with the clipped pipeline above.


::: {.sourceClojure}
```clojure
(let [;; No-clip: skip clipping, go straight from raw splits to features
      noclip-train-c  (c-prepare dag-train-c :poly+trig)
      noclip-test-c   (c-prepare dag-test-c :poly+trig)
      noclip-model-c  (c-train noclip-train-c cart-spec)
      noclip-metrics  @(c-evaluate noclip-test-c noclip-model-c)
      ;; Clean baseline: same structure, data without outliers
      clean-data-c    (pocket/cached #'make-regression-data
                                     {:f #'nonlinear-fn :n 200 :noise-sd 0.3 :seed 99})
      clean-split-c   (pocket/cached #'split-dataset clean-data-c {:seed 99})
      clean-train-c   (c-prepare (pocket/cached :train clean-split-c) :poly+trig)
      clean-test-c    (c-prepare (pocket/cached :test clean-split-c) :poly+trig)
      clean-model-c   (c-train clean-train-c cart-spec)
      clean-metrics   @(c-evaluate clean-test-c clean-model-c)]
  {:clean            clean-metrics
   :outliers-no-clip noclip-metrics
   :outliers-clipped @metrics-c})
```
:::



::: {.callout-note}
## OUT
```
22:14:32.223 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/prepare-features
22:14:32.224 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.224 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/prepare-features
22:14:32.228 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/81/81bd64358cce9b4ef112b6e4b16b04cb1cdfb14e
  Evaluating model...
22:14:32.230 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/prepare-features
22:14:32.230 INFO scicloj.pocket.impl.cache - Cache miss, computing: :test
22:14:32.230 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/split-dataset
22:14:32.230 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/make-regression-data
22:14:32.230 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/55/(pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :seed 99})
22:14:32.232 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/87/(pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :seed 99}) {:seed 99})
22:14:32.232 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/80/(:test (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :seed 99}) {:seed 99}))
22:14:32.232 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/train-model
22:14:32.232 INFO scicloj.pocket.impl.cache - Cache miss (mem), computing: pocket-book.ml-workflows/prepare-features
22:14:32.232 INFO scicloj.pocket.impl.cache - Cache miss, computing: :train
22:14:32.233 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/54/(:train (pocket-book.ml-workflows_split-dataset (pocket-book.ml-workflows_make-regression-data {:f #'pocket-book.ml-workflows_nonlinear-fn, :n 200, :noise-sd 0.3, :seed 99}) {:seed 99}))
22:14:32.237 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/a0/a076e329e7ab037718d99d2a664dfc9114879d46
  Evaluating model...

```
:::



::: {.printedClojure}
```clojure
{:clean {:rmse 0.4263098047865239},
 :outliers-no-clip {:rmse 2.552495499444297},
 :outliers-clipped {:rmse 1.601302555211606}}

```
:::


Clipping x before building polynomial features makes a visible
difference — the amplification through x² is tamed.

---


## Part 5 — Comparing many experiments at once

*Hyperparameters* are settings you choose before training: tree
depth, learning rate, which features to use. Finding good values
usually means trying many combinations — a *hyperparameter sweep*.

Pocket's `compare-experiments` helps here. You pass a collection
of cached experiments, and it extracts the parameters that vary
across them (ignoring ones that are constant).


::: {.sourceClojure}
```clojure
(defn run-pipeline
  "Run a complete pipeline with given hyperparameters."
  [{:keys [noise-sd feature-set max-depth]}]
  (let [ds (make-regression-data {:f nonlinear-fn :n 200 :noise-sd noise-sd :seed 42})
        sp (split-dataset ds {:seed 42})
        train-prep (prepare-features (:train sp) feature-set)
        test-prep (prepare-features (:test sp) feature-set)
        spec {:model-type :scicloj.ml.tribuo/regression
              :tribuo-components [{:name "cart"
                                   :type "org.tribuo.regression.rtree.CARTRegressionTrainer"
                                   :properties {:maxDepth (str max-depth)}}]
              :tribuo-trainer-name "cart"}
        model (ml/train train-prep spec)
        pred (ml/predict test-prep model)]
    {:rmse (loss/rmse (:y test-prep) (:y pred))}))
```
:::


Run experiments across a grid of hyperparameters:


::: {.sourceClojure}
```clojure
(def experiments
  (for [noise-sd [0.3 0.5]
        feature-set [:raw :poly+trig]
        max-depth [4 8]]
    (pocket/cached #'run-pipeline
                   {:noise-sd noise-sd
                    :feature-set feature-set
                    :max-depth max-depth})))
```
:::


Compare all experiments — only varying parameters are shown:


::: {.sourceClojure}
```clojure
(def comparison
  (pocket/compare-experiments experiments))
```
:::



::: {.callout-note}
## OUT
```
22:14:32.247 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.251 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/0f/(pocket-book.ml-workflows_run-pipeline {:feature-set :raw, :max-depth 4, :noise-sd 0.3})
22:14:32.251 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.255 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/23/(pocket-book.ml-workflows_run-pipeline {:feature-set :raw, :max-depth 8, :noise-sd 0.3})
22:14:32.255 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.262 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/3f/(pocket-book.ml-workflows_run-pipeline {:feature-set :poly+trig, :max-depth 4, :noise-sd 0.3})
22:14:32.262 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.268 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/40/(pocket-book.ml-workflows_run-pipeline {:feature-set :poly+trig, :max-depth 8, :noise-sd 0.3})
22:14:32.269 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.277 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/c8/(pocket-book.ml-workflows_run-pipeline {:feature-set :raw, :max-depth 4, :noise-sd 0.5})
22:14:32.277 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.282 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/01/(pocket-book.ml-workflows_run-pipeline {:feature-set :raw, :max-depth 8, :noise-sd 0.5})
22:14:32.282 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.287 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/b3/(pocket-book.ml-workflows_run-pipeline {:feature-set :poly+trig, :max-depth 4, :noise-sd 0.5})
22:14:32.287 INFO scicloj.pocket.impl.cache - Cache miss, computing: pocket-book.ml-workflows/run-pipeline
22:14:32.293 DEBUG scicloj.pocket.impl.cache - Cache write: /tmp/pocket-regression/00/(pocket-book.ml-workflows_run-pipeline {:feature-set :poly+trig, :max-depth 8, :noise-sd 0.5})

```
:::



::: {.sourceClojure}
```clojure
(tc/dataset comparison)
```
:::


::: {.clay-dataset}
_unnamed [8 4]:

| :noise-sd | :feature-set | :max-depth |                     :result |
|----------:|--------------|-----------:|-----------------------------|
|       0.3 |         :raw |          4 |  {:rmse 0.7189521159338053} |
|       0.3 |         :raw |          8 | {:rmse 0.41024324994778005} |
|       0.3 |   :poly+trig |          4 |  {:rmse 0.5297031491020386} |
|       0.3 |   :poly+trig |          8 |  {:rmse 0.4530388384300822} |
|       0.5 |         :raw |          4 |  {:rmse 0.8815492449083825} |
|       0.5 |         :raw |          8 |  {:rmse 0.6467985374993637} |
|       0.5 |   :poly+trig |          4 |  {:rmse 0.7728233864192875} |
|       0.5 |   :poly+trig |          8 |  {:rmse 0.6785270538736407} |


:::


Each row shows the varying parameters plus the result. Parameters
that were constant (like seed=42) are excluded automatically —
you see only what differs.


### Results visualization


::: {.sourceClojure}
```clojure
(let [rows (map (fn [exp]
                  (merge (select-keys exp [:noise-sd :feature-set :max-depth])
                         (:result exp)))
                comparison)
      ;; Group by both feature-set and noise-sd for legend entries
      grouped (group-by (juxt :feature-set :noise-sd) rows)
      feature-colors {:raw "steelblue" :poly "tomato" :poly+trig "green"}]
  (kind/plotly
   {:data (vec (for [[[feature-set noise-sd] pts] (sort-by first grouped)
                     :let [max-depths (mapv :max-depth pts)
                           rmses (mapv :rmse pts)]]
                 {:x max-depths
                  :y rmses
                  :mode "markers"
                  :name (str (name feature-set) " (noise=" noise-sd ")")
                  :legendgroup (name feature-set)
                  :marker {:size (+ 8 (* 15 noise-sd))
                           :color (feature-colors feature-set)}}))

    :layout {:xaxis {:title "max-depth"} :yaxis {:title "rmse"}}}))
```
:::



```{=html}
<div style="height:auto;width:100%;"><script>Plotly.newPlot(document.currentScript.parentElement, [{"x":[4,8],"y":[0.5297031491020386,0.4530388384300822],"mode":"markers","name":"poly+trig (noise=0.3)","legendgroup":"poly+trig","marker":{"size":12.5,"color":"green"}},{"x":[4,8],"y":[0.7728233864192875,0.6785270538736407],"mode":"markers","name":"poly+trig (noise=0.5)","legendgroup":"poly+trig","marker":{"size":15.5,"color":"green"}},{"x":[4,8],"y":[0.7189521159338053,0.41024324994778005],"mode":"markers","name":"raw (noise=0.3)","legendgroup":"raw","marker":{"size":12.5,"color":"steelblue"}},{"x":[4,8],"y":[0.8815492449083825,0.6467985374993637],"mode":"markers","name":"raw (noise=0.5)","legendgroup":"raw","marker":{"size":15.5,"color":"steelblue"}}], {"xaxis":{"title":"max-depth"},"yaxis":{"title":"rmse"}}, {});</script></div>
```



## What we learned

This experiment revealed a clear story about the interplay between
models, features, and noise:


- **Feature engineering is decisive for linear models.** With raw
  features, the linear model couldn't capture the nonlinear target
  at all. Adding trigonometric features (sin, cos) — which match
  the structure of the true function — dramatically improved it.
  The model didn't get smarter; we gave it the right vocabulary.


- **Decision trees are self-sufficient but fragile.** The CART model
  achieved low error regardless of feature set, because it can
  learn nonlinear splits on its own. But as noise increased, it
  began fitting the noise rather than the signal — a classic
  overfitting pattern.


- **The crossover point matters.** At low noise, the tree wins. At
  high noise, the well-featured linear model degrades more
  gracefully. Knowing where this crossover happens is exactly the
  kind of insight you get from systematic experimentation.


- **Caching structures the workflow.** In this small example, each
  step runs in milliseconds — caching isn't needed for speed. But
  the pattern scales: with real datasets and expensive training,
  the same pipeline structure ensures that only changed steps
  recompute. Meanwhile, `compare-experiments` extracted the varying
  parameters automatically, turning cached results into a
  comparison table — useful at any scale.


- **Preprocessing order matters.** Outlier x values get amplified
  by polynomial features (x²), so clipping must come *before*
  feature engineering. The diamond dependency — one threshold
  feeding both train and test clipping — is handled naturally
  by Pocket's DAG.


## Cleanup


::: {.sourceClojure}
```clojure
(pocket/cleanup!)
```
:::



::: {.callout-note}
## OUT
```
22:14:32.303 INFO scicloj.pocket - Cache cleanup: /tmp/pocket-regression

```
:::



::: {.printedClojure}
```clojure
{:dir "/tmp/pocket-regression", :existed true}

```
:::



```{=html}
<div style="background-color:grey;height:2px;width:100%;"></div>
```



```{=html}
<div><pre><small><small>source: <a href="https://github.com/scicloj/pocket/blob/master/notebooks/pocket_book/ml_workflows.clj">notebooks/pocket_book/ml_workflows.clj</a></small></small></pre></div>
```